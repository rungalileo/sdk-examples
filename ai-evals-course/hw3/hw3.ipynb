{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bdee923",
   "metadata": {},
   "source": [
    "# Homework Assignment 3: LLM-as-Judge for Recipe Bot Evaluation\n",
    "\n",
    "This notebook shows you how to run the third homework example using Galileo. This homework involves creating your own LLM-as-a-judge prompt to validate if the response from the recipe chatbot follows the users dietary restrictions.\n",
    "\n",
    "This homework example has three possible starting points, and this notebook is taking option three, starting from an already labelled data set. If you want to start with the other options, work through them to create the labelled data set, then use that instead of the pre-created labelled data set.\n",
    "\n",
    "## Configuration\n",
    "\n",
    "To be able to run this notebook, you need to have a Galileo account set up, along with an LLM integration to run an experiment to generate responses.\n",
    "\n",
    "1. If you don't have a Galileo account, head to [app.galileo.ai/sign-up](https://app.galileo.ai/sign-up) and sign up for a free account\n",
    "1. Once you have signed up, you will need to configure an LLM integration. Head to the [integrations page](https://app.galileo.ai/settings/integrations) and configure your integration of choice. The notebook assumes you are using OpenAI, but has details on what to change if you are using a different LLM.\n",
    "1. Create a Galileo API key from the [API keys page](https://app.galileo.ai/settings/api-keys)\n",
    "1. In this folder is an example `.env` file called `.env.example`. Copy this file to `.env`, and set the value of `GALILEO_API_KEY` to the API key you just created.\n",
    "1. If you are using a custom Galileo deployment inside your organization, then set the `GALILEO_CONSOLE_URL` environment variable to your console URL. If you are using [app.galileo.ai](https://app.galileo.ai), such as with the free tier, then you can leave this commented out.\n",
    "1. This code uses OpenAI to generate some values. Update the `OPENAI_API_KEY` value in the `.env` file with your OpenAI API key. If you are using another LLM, you will need to update the code to reflect this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24e3bf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (1.2.1)\n",
      "Requirement already satisfied: pydantic in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (2.12.5)\n",
      "Requirement already satisfied: galileo[openai] in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (1.37.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo[openai]) (25.4.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=2.2.1 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo[openai]) (2.2.1)\n",
      "Requirement already satisfied: galileo-core<4.0.0,>=3.75.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo[openai]) (3.76.0)\n",
      "Requirement already satisfied: openai in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo[openai]) (2.13.0)\n",
      "Requirement already satisfied: openai-agents in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo[openai]) (0.6.3)\n",
      "Requirement already satisfied: packaging<25.0,>=24.2 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo[openai]) (24.2)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo[openai]) (2.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo[openai]) (2.9.0.post0)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo[openai]) (1.17.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from pydantic) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: httpx<0.29.0,>=0.27.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo-core<4.0.0,>=3.75.0->galileo[openai]) (0.28.1)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.2.1 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo-core<4.0.0,>=3.75.0->galileo[openai]) (2.12.0)\n",
      "Requirement already satisfied: uvloop<0.22.0,>=0.21.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from galileo-core<4.0.0,>=3.75.0->galileo[openai]) (0.21.0)\n",
      "Requirement already satisfied: anyio in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from httpx<0.29.0,>=0.27.0->galileo-core<4.0.0,>=3.75.0->galileo[openai]) (4.12.0)\n",
      "Requirement already satisfied: certifi in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from httpx<0.29.0,>=0.27.0->galileo-core<4.0.0,>=3.75.0->galileo[openai]) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from httpx<0.29.0,>=0.27.0->galileo-core<4.0.0,>=3.75.0->galileo[openai]) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from httpx<0.29.0,>=0.27.0->galileo-core<4.0.0,>=3.75.0->galileo[openai]) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<0.29.0,>=0.27.0->galileo-core<4.0.0,>=3.75.0->galileo[openai]) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.8.0->galileo[openai]) (1.17.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from openai->galileo[openai]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from openai->galileo[openai]) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from openai->galileo[openai]) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from openai->galileo[openai]) (4.67.1)\n",
      "Requirement already satisfied: griffe<2,>=1.5.6 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from openai-agents->galileo[openai]) (1.15.0)\n",
      "Requirement already satisfied: mcp<2,>=1.11.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from openai-agents->galileo[openai]) (1.24.0)\n",
      "Requirement already satisfied: requests<3,>=2.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from openai-agents->galileo[openai]) (2.32.5)\n",
      "Requirement already satisfied: types-requests<3,>=2.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from openai-agents->galileo[openai]) (2.32.4.20250913)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from griffe<2,>=1.5.6->openai-agents->galileo[openai]) (0.4.6)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from mcp<2,>=1.11.0->openai-agents->galileo[openai]) (0.4.3)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from mcp<2,>=1.11.0->openai-agents->galileo[openai]) (4.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from mcp<2,>=1.11.0->openai-agents->galileo[openai]) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from mcp<2,>=1.11.0->openai-agents->galileo[openai]) (3.0.4)\n",
      "Requirement already satisfied: starlette>=0.27 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from mcp<2,>=1.11.0->openai-agents->galileo[openai]) (0.50.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from mcp<2,>=1.11.0->openai-agents->galileo[openai]) (0.38.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from requests<3,>=2.0->openai-agents->galileo[openai]) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from requests<3,>=2.0->openai-agents->galileo[openai]) (2.6.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents->galileo[openai]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents->galileo[openai]) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents->galileo[openai]) (0.30.0)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents->galileo[openai]) (46.0.3)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents->galileo[openai]) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from cffi>=2.0.0->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents->galileo[openai]) (2.23)\n",
      "Requirement already satisfied: click>=7.0 in /Users/jimbobbennett/github/sdk-examples/ai-evals-course/.venv/lib/python3.13/site-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents->galileo[openai]) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the galileo and python-dotenv package into the current Jupyter kernel\n",
    "%pip install \"galileo[openai]\" python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88c830",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "To use Galileo, we need to load the API key from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1de277e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check that the GALILEO_API_KEY environment variable is set\n",
    "if not os.getenv(\"GALILEO_API_KEY\"):\n",
    "    raise ValueError(\"GALILEO_API_KEY environment variable is not set. Please set it in your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67044c89",
   "metadata": {},
   "source": [
    "Next we need to ensure there is a Galileo project set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "909e5b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project: AI Evals Course - Homework 3 (ID: a56824ba-12e4-4d41-9a0a-57deee0b84ea)\n"
     ]
    }
   ],
   "source": [
    "from galileo.projects import create_project, get_project\n",
    "\n",
    "PROJECT_NAME = \"AI Evals Course - Homework 3\"\n",
    "project = get_project(name=PROJECT_NAME)\n",
    "if project is None:\n",
    "    project = create_project(name=PROJECT_NAME)\n",
    "\n",
    "print(f\"Using project: {project.name} (ID: {project.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243820e",
   "metadata": {},
   "source": [
    "In this notebook, you will be using the LLM integration you set up in Galileo to run an experiment, as well as calling OpenAI directly to generate some data. The default model used is GPT-5.1, and this assumes you have configured an OpenAI integration.\n",
    "\n",
    "If you have another integration set up, or want to use a different model, update this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76da60ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"gpt-5.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f47e3",
   "metadata": {},
   "source": [
    "## Step 2: Split your data (skipping step 1)\n",
    "\n",
    "We are starting at step 2, using the already labelled data set. We'll start by loading the data set, and divide into pass and fail sets. We divide into pass and fail to run each as a separate experiment, so that it is easier to see the true positive and true negative traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5054679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total traces: 101\n",
      "Passed traces: 75\n",
      "Failed traces: 26\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Load the labelled traces\n",
    "source_path = \"https://raw.githubusercontent.com/ai-evals-course/recipe-chatbot/refs/heads/main/homeworks/hw3/reference_files/labeled_traces.jsonl\"\n",
    "\n",
    "# Open and read the labelled traces into a JSON array\n",
    "with urlopen(source_path) as resp:\n",
    "    lines = (ln.decode(\"utf-8\") for ln in resp)\n",
    "    labelled_traces = [json.loads(line) for line in lines]\n",
    "\n",
    "# Divide into pass and fail sets. These are defined by the label property as PASS or FAIL.\n",
    "passed_traces = [trace for trace in labelled_traces if trace[\"label\"] == \"PASS\"]\n",
    "failed_traces = [trace for trace in labelled_traces if trace[\"label\"] == \"FAIL\"]\n",
    "\n",
    "print(f\"Total traces: {len(labelled_traces)}\")\n",
    "print(f\"Passed traces: {len(passed_traces)}\")\n",
    "print(f\"Failed traces: {len(failed_traces)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d064c259",
   "metadata": {},
   "source": [
    "Now for each set, split into 10% train, 40% dev, and 50% test. Do this randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22fb8e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed split: Train=7 Dev=30 Test=38 (total=75)\n",
      "Failed split: Train=2 Dev=10 Test=14 (total=26)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def split_traces(traces, train_frac=0.10, dev_frac=0.40, seed=42, name=None):\n",
    "    rng = random.Random(seed)\n",
    "    shuffled = traces.copy()\n",
    "    rng.shuffle(shuffled)\n",
    "    total = len(shuffled)\n",
    "    train_size = int(total * train_frac)\n",
    "    dev_size = int(total * dev_frac)\n",
    "    train = shuffled[:train_size]\n",
    "    dev = shuffled[train_size:train_size + dev_size]\n",
    "    test = shuffled[train_size + dev_size:]\n",
    "    label = f\"{name} \" if name else \"\"\n",
    "    print(f\"{label}split: Train={len(train)} Dev={len(dev)} Test={len(test)} (total={total})\")\n",
    "    return train, dev, test\n",
    "\n",
    "# Split passed and failed traces into train/dev/test sets\n",
    "passed_train, passed_dev, passed_test = split_traces(passed_traces, name=\"Passed\")\n",
    "failed_train, failed_dev, failed_test = split_traces(failed_traces, name=\"Failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fbadbf",
   "metadata": {},
   "source": [
    "To make it easier to view the data, let's upload these as datasets in Galileo. First let's create unique names for these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dd9646f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed training set name: Homework 3 Passed training set - 2025-12-17 19:17:17\n",
      "Failed training set name: Homework 3 Failed training set - 2025-12-17 19:17:17\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "PASSED_TRAINING_SET_NAME = f\"Homework 3 Passed training set - {current_time}\"\n",
    "FAILED_TRAINING_SET_NAME = f\"Homework 3 Failed training set - {current_time}\"\n",
    "\n",
    "print(f\"Passed training set name: {PASSED_TRAINING_SET_NAME}\")\n",
    "print(f\"Failed training set name: {FAILED_TRAINING_SET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d226189d",
   "metadata": {},
   "source": [
    "Next we create the actual datasets, with the query, response, and some additional information as metadata, such as the reasoning behind the label.\n",
    "\n",
    "A link to the datasets is output after they are created, so you can view these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb89c549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists with ID: 2c7c66c3-e8fb-447c-a67d-7b55bd2b9382, deleting it to re-create.\n",
      "Dataset already exists with ID: 2f515ce2-ec3e-46c3-a462-086205166da7, deleting it to re-create.\n",
      "Dataset created. You can view it at https://app.galileo.ai/datasets/d91a6ceb-d516-4ca0-99bc-bee2992a1081\n",
      "Dataset created. You can view it at https://app.galileo.ai/datasets/3ef1ef48-2f5b-4459-b49a-fe6b95a7f49b\n"
     ]
    }
   ],
   "source": [
    "from galileo.datasets import get_dataset, create_dataset, delete_dataset\n",
    "\n",
    "def create_training_set_dataset(dataset_name, rows):\n",
    "\n",
    "    # Now we have the CSV file loaded, lets create a dataset. If the dataset already exists, we will delete it and re-create it.\n",
    "    dataset = get_dataset(\n",
    "        name=dataset_name\n",
    "    )\n",
    "\n",
    "    if dataset is not None:\n",
    "        print(f\"Dataset already exists with ID: {dataset.id}, deleting it to re-create.\")\n",
    "        dataset = delete_dataset(\n",
    "            name=dataset_name\n",
    "        )\n",
    "\n",
    "    dataset = create_dataset(\n",
    "        name=dataset_name,\n",
    "        content=[\n",
    "            {\n",
    "                \"input\": row[\"query\"],\n",
    "                \"output\": row[\"response\"],\n",
    "                \"metadata\": {\n",
    "                    \"query_id\": row[\"query_id\"],\n",
    "                    \"reasoning\": row[\"reasoning\"],\n",
    "                },\n",
    "            } for row in rows\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# Create the passed and failed training set datasets\n",
    "passed_dataset = create_training_set_dataset(\n",
    "    dataset_name=PASSED_TRAINING_SET_NAME,\n",
    "    rows=passed_train\n",
    ")\n",
    "failed_dataset = create_training_set_dataset(\n",
    "    dataset_name=FAILED_TRAINING_SET_NAME,\n",
    "    rows=failed_train\n",
    ")\n",
    "\n",
    "print(f\"Passed training dataset created. You can view it at {os.environ.get('GALILEO_CONSOLE_URL', 'https://app.galileo.ai/').removesuffix('/')}/datasets/{passed_dataset.id}\")\n",
    "print(f\"Failed training dataset created. You can view it at {os.environ.get('GALILEO_CONSOLE_URL', 'https://app.galileo.ai/').removesuffix('/')}/datasets/{failed_dataset.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229d08a",
   "metadata": {},
   "source": [
    "## Step 3: Write your judge prompt\n",
    "\n",
    "Now we have the train, dev, and test data sets, we can build the LLM-as-a-judge prompt.\n",
    "\n",
    "Update the `custom_metric_prompt` below with your judge prompt. Remember to include:\n",
    "- The task and criterion\n",
    "- Clear Pass/Fail definitions\n",
    "- 2-3 few-shot examples from your Train set with input, output, reasoning, and pass/fail label. Refer to the datasets created in the last section for these.\n",
    "\n",
    "For the expected output, the metric should return `true` if the output follows the dietary restrictions defined in the input, otherwise return `false`.\n",
    "\n",
    "This prompt will be used by Galileo to evaluate the outputs. Refer to the [LLM-as-a-judge prompt engineering guide in the Galileo documentation](https://v2docs.galileo.ai/concepts/metrics/custom-metrics/prompt-engineering) for more guidance on how to structure a good LLM-as-a-judge prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbdc3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt for the custom dietary adherence metric.\n",
    "# Make sure to fill in the examples section with relevant examples from the training datasets, with both pass and fail examples.\n",
    "custom_metric_prompt = \"\"\"\n",
    "You are an expert nutritionist and dietary specialist evaluating whether recipe responses properly adhere to specified dietary restrictions.\n",
    "\n",
    "DIETARY RESTRICTION DEFINITIONS:\n",
    "- Vegan: No animal products (meat, dairy, eggs, honey, etc.)\n",
    "- Vegetarian: No meat or fish, but dairy and eggs are allowed\n",
    "- Gluten-free: No wheat, barley, rye, or other gluten-containing grains\n",
    "- Dairy-free: No milk, cheese, butter, yogurt, or other dairy products\n",
    "- Keto: Very low carb (typically <20g net carbs), high fat, moderate protein\n",
    "- Paleo: No grains, legumes, dairy, refined sugar, or processed foods\n",
    "- Pescatarian: No meat except fish and seafood\n",
    "- Kosher: Follows Jewish dietary laws (no pork, shellfish, mixing meat/dairy)\n",
    "- Halal: Follows Islamic dietary laws (no pork, alcohol, proper slaughter)\n",
    "- Nut-free: No tree nuts or peanuts\n",
    "- Low-carb: Significantly reduced carbohydrates (typically <50g per day)\n",
    "- Sugar-free: No added sugars or high-sugar ingredients\n",
    "- Raw vegan: Vegan foods not heated above 118°F (48°C)\n",
    "- Whole30: No grains, dairy, legumes, sugar, alcohol, or processed foods\n",
    "- Diabetic-friendly: Low glycemic index, controlled carbohydrates\n",
    "- Low-sodium: Reduced sodium content for heart health\n",
    "\n",
    "Rubric:\n",
    "- true: The recipe in the output clearly adheres to the dietary preferences defined in the input with appropriate ingredients and preparation methods\n",
    "- false: The recipe in the output contains ingredients or methods that violate the dietary preferences defined in the input\n",
    "- Consider both explicit ingredients and cooking methods\n",
    "\n",
    "Here are some examples of how to evaluate dietary adherence:\n",
    "\n",
    "1.\n",
    "2.\n",
    "3.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
